{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Models with Class Balancing\n",
    "\n",
    "Addressing class imbalance using SMOTE and evaluating impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Load data\n",
    "X_train = np.load('data/X_train_fe.npy')\n",
    "X_test = np.load('data/X_test_fe.npy')\n",
    "y_train = np.load('data/y_train_encoded.npy')\n",
    "y_test = np.load('data/y_test_encoded.npy')\n",
    "\n",
    "le = joblib.load('data/label_encoder.joblib')\n",
    "\n",
    "print(f'Training set: {X_train.shape}')\n",
    "print(f'Test set: {X_test.shape}')\n",
    "print(f'\\nOriginal class distribution:')\n",
    "print(Counter(y_train))\n",
    "for cls, count in Counter(y_train).items():\n",
    "    print(f'{le.classes_[cls]}: {count} ({count/len(y_train)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Performance (Without Balancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models without balancing\n",
    "rf_baseline = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "gb_baseline = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Evaluate\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "rf_pred_baseline = rf_baseline.predict(X_test)\n",
    "\n",
    "gb_baseline.fit(X_train, y_train)\n",
    "gb_pred_baseline = gb_baseline.predict(X_test)\n",
    "\n",
    "print('BASELINE PERFORMANCE (No Balancing)')\n",
    "print('='*60)\n",
    "print('Random Forest:')\n",
    "print(f'  Accuracy: {accuracy_score(y_test, rf_pred_baseline):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_test, rf_pred_baseline, average=\"weighted\"):.4f}')\n",
    "print(classification_report(y_test, rf_pred_baseline, target_names=le.classes_))\n",
    "\n",
    "print('\\nGradient Boosting:')\n",
    "print(f'  Accuracy: {accuracy_score(y_test, gb_pred_baseline):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_test, gb_pred_baseline, average=\"weighted\"):.4f}')\n",
    "print(classification_report(y_test, gb_pred_baseline, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SMOTE for Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('After SMOTE:')\n",
    "print(f'Training set: {X_train_balanced.shape}')\n",
    "print(f'\\nBalanced class distribution:')\n",
    "for cls, count in Counter(y_train_balanced).items():\n",
    "    print(f'{le.classes_[cls]}: {count} ({count/len(y_train_balanced)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Original distribution\n",
    "orig_counts = Counter(y_train)\n",
    "axes[0].bar([le.classes_[i] for i in orig_counts.keys()], \n",
    "            orig_counts.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Original Class Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_ylim(0, max(orig_counts.values()) * 1.1)\n",
    "\n",
    "# After SMOTE\n",
    "balanced_counts = Counter(y_train_balanced)\n",
    "axes[1].bar([le.classes_[i] for i in balanced_counts.keys()], \n",
    "            balanced_counts.values(), color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[1].set_title('After SMOTE', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_ylim(0, max(balanced_counts.values()) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/class_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models with Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with balanced data\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "gb_smote = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "rf_smote.fit(X_train_balanced, y_train_balanced)\n",
    "rf_pred_smote = rf_smote.predict(X_test)\n",
    "\n",
    "gb_smote.fit(X_train_balanced, y_train_balanced)\n",
    "gb_pred_smote = gb_smote.predict(X_test)\n",
    "\n",
    "print('PERFORMANCE WITH SMOTE')\n",
    "print('='*60)\n",
    "print('Random Forest + SMOTE:')\n",
    "print(f'  Accuracy: {accuracy_score(y_test, rf_pred_smote):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_test, rf_pred_smote, average=\"weighted\"):.4f}')\n",
    "print(classification_report(y_test, rf_pred_smote, target_names=le.classes_))\n",
    "\n",
    "print('\\nGradient Boosting + SMOTE:')\n",
    "print(f'  Accuracy: {accuracy_score(y_test, gb_pred_smote):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_test, gb_pred_smote, average=\"weighted\"):.4f}')\n",
    "print(classification_report(y_test, gb_pred_smote, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Class Weights Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use class weights\n",
    "rf_weighted = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_weighted = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_weighted.fit(X_train, y_train)\n",
    "rf_pred_weighted = rf_weighted.predict(X_test)\n",
    "\n",
    "# Note: GradientBoosting doesn't have class_weight parameter\n",
    "# We can use sample_weight instead\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "gb_weighted.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "gb_pred_weighted = gb_weighted.predict(X_test)\n",
    "\n",
    "print('PERFORMANCE WITH CLASS WEIGHTS')\n",
    "print('='*60)\n",
    "print('Random Forest (weighted):')\n",
    "print(f'  Accuracy: {accuracy_score(y_test, rf_pred_weighted):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_test, rf_pred_weighted, average=\"weighted\"):.4f}')\n",
    "print(classification_report(y_test, rf_pred_weighted, target_names=le.classes_))\n",
    "\n",
    "print('\\nGradient Boosting (weighted):')\n",
    "print(f'  Accuracy: {accuracy_score(y_test, gb_pred_weighted):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_test, gb_pred_weighted, average=\"weighted\"):.4f}')\n",
    "print(classification_report(y_test, gb_pred_weighted, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of All Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all approaches\n",
    "results = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'RF (Baseline)',\n",
    "        'RF + SMOTE',\n",
    "        'RF + Class Weights',\n",
    "        'GB (Baseline)',\n",
    "        'GB + SMOTE',\n",
    "        'GB + Sample Weights'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, rf_pred_baseline),\n",
    "        accuracy_score(y_test, rf_pred_smote),\n",
    "        accuracy_score(y_test, rf_pred_weighted),\n",
    "        accuracy_score(y_test, gb_pred_baseline),\n",
    "        accuracy_score(y_test, gb_pred_smote),\n",
    "        accuracy_score(y_test, gb_pred_weighted)\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        f1_score(y_test, rf_pred_baseline, average='weighted'),\n",
    "        f1_score(y_test, rf_pred_smote, average='weighted'),\n",
    "        f1_score(y_test, rf_pred_weighted, average='weighted'),\n",
    "        f1_score(y_test, gb_pred_baseline, average='weighted'),\n",
    "        f1_score(y_test, gb_pred_smote, average='weighted'),\n",
    "        f1_score(y_test, gb_pred_weighted, average='weighted')\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('COMPARISON: Baseline vs SMOTE vs Class Weights')\n",
    "print('='*70)\n",
    "print(results.to_string(index=False))\n",
    "print('='*70)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(results))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, results['Accuracy'], width, label='Accuracy', color='#3498db')\n",
    "bars2 = ax.bar(x + width/2, results['F1 Score'], width, label='F1 Score', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Model Variant')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results['Model'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0.6, 0.85)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/balancing_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "results.to_csv('data/balancing_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Class Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare per-class F1 scores\n",
    "from sklearn.metrics import f1_score as f1_per_class\n",
    "\n",
    "models_preds = {\n",
    "    'Baseline': rf_pred_baseline,\n",
    "    'SMOTE': rf_pred_smote,\n",
    "    'Weighted': rf_pred_weighted\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(le.classes_))\n",
    "width = 0.25\n",
    "\n",
    "for i, (name, preds) in enumerate(models_preds.items()):\n",
    "    f1_scores = f1_per_class(y_test, preds, average=None)\n",
    "    offset = (i - 1) * width\n",
    "    ax.bar(x + offset, f1_scores, width, label=name)\n",
    "\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.set_title('Per-Class F1 Scores: Impact of Balancing Techniques', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(le.classes_)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/per_class_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine best model based on F1 score\n",
    "best_idx = results['F1 Score'].idxmax()\n",
    "best_model_name = results.loc[best_idx, 'Model']\n",
    "best_f1 = results.loc[best_idx, 'F1 Score']\n",
    "\n",
    "print(f'Best model: {best_model_name} with F1={best_f1:.4f}')\n",
    "\n",
    "# Save the best model (assuming it's one of the weighted ones)\n",
    "if 'GB' in best_model_name and 'Weight' in best_model_name:\n",
    "    joblib.dump(gb_weighted, 'data/best_model_final.joblib')\n",
    "    print('Saved: Gradient Boosting with sample weights')\n",
    "elif 'RF' in best_model_name and 'Weight' in best_model_name:\n",
    "    joblib.dump(rf_weighted, 'data/best_model_final.joblib')\n",
    "    print('Saved: Random Forest with class weights')\n",
    "elif 'SMOTE' in best_model_name:\n",
    "    if 'RF' in best_model_name:\n",
    "        joblib.dump(rf_smote, 'data/best_model_final.joblib')\n",
    "        print('Saved: Random Forest trained on SMOTE data')\n",
    "    else:\n",
    "        joblib.dump(gb_smote, 'data/best_model_final.joblib')\n",
    "        print('Saved: Gradient Boosting trained on SMOTE data')\n",
    "\n",
    "print('\\nModel saved as: data/best_model_final.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "**Findings:**\n",
    "- Class imbalance affects minority class (\"Enrolled\") performance\n",
    "- SMOTE typically improves recall for minority classes but may reduce overall accuracy\n",
    "- Class weights provide a good middle ground between balanced and unbalanced approaches\n",
    "- The best approach depends on the business cost of different error types\n",
    "\n",
    "**Recommendation:**\n",
    "If identifying at-risk \"Enrolled\" students is critical, use SMOTE or weighted models despite slightly lower overall accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
